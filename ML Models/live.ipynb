{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raghav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained digit recognition model.\n",
      "Math Problem: 4 + 3\n",
      "Please solve this problem and write the answer clearly within the designated circular area of the camera frame.\n",
      "Multiple faces detected!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "# Initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Blink detection function\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Lighting check function\n",
    "def check_lighting(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    brightness = hsv[..., 2].mean()\n",
    "    if brightness < 50:\n",
    "        return \"Lighting is too low\", False\n",
    "    elif brightness > 200:\n",
    "        return \"Lighting is too bright\", False\n",
    "    return \"Lighting is fine\", True\n",
    "\n",
    "# Function to generate a random math problem\n",
    "def generate_math_problem():\n",
    "    operators = ['+', '-']\n",
    "    num1 = random.randint(1, 10)\n",
    "    num2 = random.randint(1, num1)  # Ensure a valid subtraction\n",
    "    operator = random.choice(operators)\n",
    "    problem = f\"{num1} {operator} {num2}\"\n",
    "    correct_answer = eval(problem)\n",
    "    return problem, correct_answer\n",
    "\n",
    "# Preprocess image for CNN (resize to 28x28 for digit recognition)\n",
    "def preprocess_image_for_cnn(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized_image = cv2.resize(gray, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    normalized_image = resized_image / 255.0  # Normalize pixel values\n",
    "    reshaped_image = normalized_image.reshape(1, 28, 28, 1)  # Shape for CNN input\n",
    "    return reshaped_image\n",
    "\n",
    "# CNN model for digit recognition\n",
    "def create_digit_recognition_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))  # Output layer for 10 digits\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train or load CNN model on MNIST dataset\n",
    "def load_or_train_digit_recognition_model():\n",
    "    try:\n",
    "        # Try to load pre-trained model weights\n",
    "        model = create_digit_recognition_model()\n",
    "        model.load_weights('digit_recognition_model.h5')\n",
    "        print(\"Loaded pre-trained digit recognition model.\")\n",
    "    except:\n",
    "        # If model does not exist, train it on the MNIST dataset and save it\n",
    "        print(\"Training a new digit recognition model...\")\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "        x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "        y_train = to_categorical(y_train, 10)\n",
    "        y_test = to_categorical(y_test, 10)\n",
    "\n",
    "        model = create_digit_recognition_model()\n",
    "        model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "        model.save_weights('digit_recognition_model.h5')  # Save model for future use\n",
    "        print(\"Saved digit recognition model.\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Capture image and save\n",
    "def capture_image(frame):\n",
    "    cv2.imwrite(\"captured_image.jpg\", frame)\n",
    "    print(\"Image captured and saved!\")\n",
    "    return frame\n",
    "\n",
    "# Main liveness detection and OCR pipeline\n",
    "def run_liveness_detection():\n",
    "    # Load or train the CNN for digit recognition\n",
    "    digit_recognition_model = load_or_train_digit_recognition_model()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Blink detection parameters\n",
    "    EYE_AR_THRESH = 0.25\n",
    "    COUNTER = 0\n",
    "    BLINKS = 0\n",
    "    MIN_BLINKS = 3\n",
    "    MAX_FRAMES_WITHOUT_BLINK = 90\n",
    "    NO_BLINK_COUNTER = 0\n",
    "    \n",
    "    # Face detection parameters\n",
    "    FACE_DETECT_FRAMES = 5\n",
    "    face_detect_counter = 0\n",
    "    face_detected = False\n",
    "\n",
    "    math_problem, correct_answer = generate_math_problem()\n",
    "    print(f\"Math Problem: {math_problem}\")\n",
    "    print(\"Please solve this problem and write the answer clearly within the designated circular area of the camera frame.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame. Exiting...\")\n",
    "            break\n",
    "\n",
    "        height, width = frame.shape[:2]\n",
    "        center = (int(width / 2), int(height * 0.85))\n",
    "        radius = int(min(width, height) * 0.15)\n",
    "\n",
    "        cv2.circle(frame, center, radius, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Place your answer here\", (center[0] - 100, center[1] - radius - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        lighting_status, correct_lighting = check_lighting(frame)\n",
    "        cv2.putText(frame, lighting_status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                    (0, 255, 0) if correct_lighting else (0, 0, 255), 2)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            face_detect_counter += 1\n",
    "            if face_detect_counter >= FACE_DETECT_FRAMES:\n",
    "                cv2.putText(frame, \"No face detected\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                face_detected = False\n",
    "        else:\n",
    "            face_detect_counter = 0\n",
    "            face_detected = True\n",
    "\n",
    "            if len(faces) > 1:\n",
    "                print(\"Multiple faces detected!\")\n",
    "                cv2.putText(frame, \"Multiple faces detected!\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                time.sleep(5)\n",
    "                break\n",
    "            else:\n",
    "                face = faces[0]\n",
    "                shape = predictor(gray, face)\n",
    "                shape = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "\n",
    "                left_eye = shape[36:42]\n",
    "                right_eye = shape[42:48]\n",
    "                leftEAR = eye_aspect_ratio(left_eye)\n",
    "                rightEAR = eye_aspect_ratio(right_eye)\n",
    "                ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= 2:\n",
    "                        BLINKS += 1\n",
    "                    COUNTER = 0\n",
    "                    NO_BLINK_COUNTER = 0\n",
    "\n",
    "                NO_BLINK_COUNTER += 1\n",
    "                if NO_BLINK_COUNTER > MAX_FRAMES_WITHOUT_BLINK:\n",
    "                    BLINKS = 0\n",
    "                    NO_BLINK_COUNTER = 0\n",
    "\n",
    "                cv2.putText(frame, f\"Blink Count: {BLINKS}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Check if all conditions are met for capture\n",
    "        if face_detected and BLINKS >= MIN_BLINKS and correct_lighting:\n",
    "            cv2.putText(frame, \"Press 'c' to capture image\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Liveness Detection & Digit Recognition\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Press 'Esc' to exit\n",
    "            break\n",
    "        elif key == ord('c') and face_detected and BLINKS >= MIN_BLINKS and correct_lighting:\n",
    "            captured_frame = capture_image(frame)\n",
    "            roi = frame[center[1] - radius:center[1] + radius, center[0] - radius:center[0] + radius]\n",
    "            \n",
    "            preprocessed_roi = preprocess_image_for_cnn(roi)\n",
    "            predicted_digit = np.argmax(digit_recognition_model.predict(preprocessed_roi))\n",
    "\n",
    "            if predicted_digit == correct_answer:\n",
    "                result_text = \"Correct answer!\"\n",
    "            else:\n",
    "                result_text = f\"Incorrect! Predicted: {predicted_digit}, Expected: {correct_answer}\"\n",
    "\n",
    "            cv2.putText(captured_frame, result_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if \"Correct\" in result_text else (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Captured Image\", captured_frame)\n",
    "            cv2.waitKey(0)\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the combined liveness detection and OCR pipeline\n",
    "run_liveness_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
